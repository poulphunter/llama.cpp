{
  "Header": {
    "deleteConfirm": "Etes vous certain de vouloir supprimer cette conversation ?",
    "downloadBtn": "Télécharger",
    "deleteBtn": "Supprimer",
    "tooltipSettings": "Configuration",
    "tooltipTheme": "Theme",
    "tooltipLanguage": "Langue",
    "manualSettings": "Configuration manuelle"
  },
  "Sidebar": {
    "Conversations": "Conversations",
    "sidebarClose": "Fermer le panneau latéral",
    "newConversation": "+ Nouvelle conversation",
    "convInformation": "Les conversations sont enregistrées dans l'IndexedDB du navigateur"
  },
  "ChatScreen": {
    "suggestions": "Voici quelques examples :",
    "sendMsgStart": "Envoyez un message pour commencer la discussion",
    "textAreaPlaceHolder": "Tappez un message (Shift+Entrer pour ajouter une nouvelle ligne)",
    "stopBtn": "Arreter",
    "sendBtn": "Envoyer"
  },
  "ChatMessage": {
    "Time": "Temps",
    "Speed": "Vitesse",
    "Tokens": "Jetons",
    "Cancel": "Annuler",
    "Submit": "Envoyer",
    "Edit": "✍\uFE0F Editer",
    "Regenerate": "\uD83D\uDD04 Régénérer",
    "Thinking": "En train de réfléchir",
    "ThoughtProcess": "Processus de réflexion",
    "ExtraContent": "Contenu supplémentaire"
  },
  "MarkdownDisplay": {
    "copied": "Copié !",
    "copy": "\uD83D\uDCCB Copier"
  },
  "config": {
    "meaning": {
      "apiKey": "Définissez la clé API si vous utilisez l’option --api-key pour le serveur.",
      "systemMessage": "Le message de départ qui définit comment le modèle doit se comporter.",
      "samplers": "L'ordre dans lequel les 'samplers' sont appliqués, de manière simplifiée. La valeur par défaut est 'dkypmxt' : dry->top_k->typ_p->top_p->min_p->xtc->temperature",
      "temperature": "Contrôle le caractère aléatoire du texte généré en affectant la distribution de probabilité des jetons de sortie. Plus élevé = plus aléatoire, plus bas = plus ciblé.",
      "dynatemp_range": "Addon pour l'échantillonneur de température. La valeur ajoutée à la plage de température dynamique, qui ajuste les probabilités par l'entropie des jetons.",
      "dynatemp_exponent": "Addon pour l'échantillonneur de température. Lisse la redistribution de probabilité en fonction du jeton le plus probable.",
      "top_k": "Conserve uniquement les k meilleurs jetons.",
      "top_p": "Limite les jetons à ceux qui ont ensemble une probabilité cumulative d'au moins p",
      "min_p": "Limite les jetons en fonction de la probabilité minimale pour qu'un jeton soit pris en compte, par rapport à la probabilité du jeton le plus probable.",
      "xtc_probability": "XTC sampler cuts out top tokens; this parameter controls the chance of cutting tokens at all. 0 disables XTC.",
      "xtc_threshold": "XTC sampler cuts out top tokens; this parameter controls the token probability that is required to cut that token.",
      "typical_p": "Sorts and limits tokens based on the difference between log-probability and entropy.",
      "repeat_last_n": "Last n tokens to consider for penalizing repetition",
      "repeat_penalty": "Controls the repetition of token sequences in the generated text",
      "presence_penalty": "Limits tokens based on whether they appear in the output or not.",
      "frequency_penalty": "Limits tokens based on how often they appear in the output.",
      "dry_multiplier": "DRY sampling reduces repetition in generated text even across long contexts. This parameter sets the DRY sampling multiplier.",
      "dry_base": "DRY sampling reduces repetition in generated text even across long contexts. This parameter sets the DRY sampling base value.",
      "dry_allowed_length": "DRY sampling reduces repetition in generated text even across long contexts. This parameter sets the allowed length for DRY sampling.",
      "dry_penalty_last_n": "DRY sampling reduces repetition in generated text even across long contexts. This parameter sets DRY penalty for the last n tokens.",
      "max_tokens": "The maximum number of token per output."
    }
  }
}
